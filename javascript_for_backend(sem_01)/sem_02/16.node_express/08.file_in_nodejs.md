# Working with Files in Node.js

## File System, Buffers, and Streams

Backend applications constantly work with data such as:

* Logs
* Uploaded files
* Reports
* Configuration files

Node.js provides **powerful APIs** to handle these tasks efficiently.

This article explains:

* How Node works with files
* Why async file operations matter
* How large data is handled without crashing servers

---

## Working with the File System (`fs` Module)

## What is the `fs` Module?

The `fs` (File System) module allows Node.js to:

* Read files
* Write files
* Update files
* Delete files

These operations happen **outside the browser**, directly on the server.

---

## Reading a File Asynchronously 

```js
const fs = require("fs");

fs.readFile("data.txt", "utf-8", (error, data) => {

  if (error) {
    console.log("Error reading file");
    return;
  }

  console.log("File content:", data);
});
```

### What is happening internally?

* Node sends file-reading work to the **libuv worker pool**
* Main thread stays free
* Callback runs after file is read

This is **safe for servers**.

---

## Writing to a File Asynchronously

```js
fs.writeFile("log.txt", "Hello from Node.js", (error) => {

  if (error) {
    console.log("Error writing file");
    return;
  }

  console.log("File written successfully");
});
```

### Common real-world uses:

* Writing logs
* Saving temporary data
* Exporting reports

---

## `writeFileSync` – Synchronous File Writing

```js
fs.writeFileSync("sync-log.txt", "This is sync write");
console.log("File written");
```

### Important Explanation

`writeFileSync`:

* Blocks the **main thread**
* Stops all other requests
* Freezes the server while writing

### When is it acceptable?

* Small scripts
* CLI tools
* One-time setup scripts

### Rule for backend servers:

> ❌ Avoid `writeFileSync`
> ✅ Prefer `writeFile`

---

## Why Sync File Methods Are Dangerous in Servers

```js
const data = fs.readFileSync("data.txt", "utf-8");
```

Problems:

* Blocks event loop
* No other request can be processed
* Poor scalability

This is **one of the most common beginner mistakes**.

---

## Buffers and Streams (Handling Large Data)


## What is a Buffer?

![Image](https://i2.wp.com/tolustar.com/wp-content/uploads/2021/06/buffer-and-stream.png?fit=1024%2C517\&ssl=1)

![Image](https://cdn.hashnode.com/res/hashnode/image/upload/v1723736378794/8525e8e1-cef9-48a0-807c-cf9b985857b6.jpeg?auto=compress%2Cformat\&format=webp)

A **Buffer** is:

* Temporary memory
* Used to store binary data
* Managed by Node.js internally

Example:

```js
const buffer = Buffer.from("Node");
console.log(buffer);
```

You usually **don’t manipulate buffers directly** — streams handle that.

---

## Why Streams Exist

Imagine reading a **very large file**.

Bad approach:

* Load entire file into memory ❌

Correct approach:

* Read it **piece by piece** ✅

This is exactly what **streams** do.

---

## Reading a File Using Streams

![Image](https://miro.medium.com/0%2AQrDkO_qFHlojbXUu.png)

![Image](https://iximiuz.com/nodejs-readable-streams-distilled/kdpv.png)

```js
const fs = require("fs");

const readStream = fs.createReadStream("bigfile.txt", "utf-8");

readStream.on("data", (chunk) => {
  console.log("Received chunk:", chunk);
});

readStream.on("end", () => {
  console.log("Finished reading file");
});
```

### What is happening?

* File is read in chunks
* Each chunk triggers a `data` event
* Memory usage stays low

---

##  Why Streams Are Important in Real Applications

Streams are used in:

* File uploads
* Video streaming
* Audio streaming
* Log processing
* Large API responses

Without streams:

* High memory usage
* Server crashes
* Poor performance

---

## Stream vs `readFile` (Simple Comparison)

| Feature      | `readFile`             | Stream      |
| ------------ | ---------------------- | ----------- |
| Memory usage | High                   | Low         |
| Speed        | Slower for large files | Faster      |
| Best for     | Small files            | Large files |

---

## How `fs` and Streams Work Together

* `fs` provides file access
* Streams read/write data efficiently
* Buffers temporarily store chunks
* Event loop coordinates execution

This combination is **core to Node.js performance**.

---

## Key Takeaways 

* `fs` enables server-side file operations
* Async methods use worker pool
* `writeFileSync` blocks the event loop
* Buffers store binary data
* Streams handle large files efficiently
* These concepts prevent server crashes

---
