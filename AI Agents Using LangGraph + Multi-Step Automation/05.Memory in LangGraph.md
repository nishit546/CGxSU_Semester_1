# Memory in LangGraph
## Memory

Memory is what allows an agent to behave **intelligently over time**. Without memory, every step would be isolated, forcing the agent to repeatedly rediscover information, forget past decisions, and lose context. In such a system, learning and adaptation are impossible.

LangGraph treats memory as a **first-class concept** through its **state system**.

Unlike traditional LLM applications—where memory is often hidden inside prompts or loosely managed through message history—LangGraph makes memory **explicit, structured, and observable**.

---

## Memory as Explicit State

In LangGraph, memory is not buried inside prompt text. Instead:

- Memory lives in the **state**
- State flows through **every node**
- Each node can read from and write to memory
- Memory evolves step by step as the agent progresses

This design makes memory:
- **Transparent** – you can see exactly what the agent knows
- **Controllable** – you decide what is stored and when
- **Debuggable** – you can inspect memory at any point in execution

---

## What Can Be Stored as Memory

Memory in LangGraph can include virtually anything relevant to the agent’s reasoning and behavior, such as:

- Previous decisions made by the agent
- Intermediate reasoning outputs
- Tool call results
- User feedback or approvals
- Flags used for branching and control flow
- Summaries of prior steps
- Error states or retry counters

Because state flows through every node, memory naturally **accumulates and evolves**. Each node contributes a small piece to the agent’s overall understanding.

---

## Why This Approach Is Powerful

This explicit memory model provides several major advantages:

- You can inspect memory at any point in the graph
- You can deliberately reset or modify memory
- You can clearly separate different kinds of memory
- You avoid accidental loss of context
- You eliminate hidden, implicit behavior

Memory becomes part of the **architecture**, not an afterthought.

---

## Memory as the Backbone of Agentic Behavior

Memory is what allows an agent to:
- Avoid repeating mistakes
- Build on previous reasoning
- Adapt its strategy
- Make informed decisions
- Behave consistently over time

Without memory, an agent is reactive.  
With memory, an agent becomes **context-aware and adaptive**.

---

## Short-Term vs Long-Term Memory

Not all memory serves the same purpose. LangGraph workflows typically distinguish between **short-term memory** and **long-term memory**.

Understanding this distinction is critical for designing scalable and efficient agentic systems.

---

## Short-Term Memory

Short-term memory refers to information that is relevant **only within the current execution of the graph**.

Examples include:
- The current task or goal
- Intermediate reasoning results
- Temporary tool outputs
- Control-flow flags
- Retry counters
- Approval decisions

### Key Characteristics
- Lives entirely in the graph’s state
- Exists only during a single run
- Discarded when execution ends
- Optimized for reasoning and flow control

Short-term memory enables the agent to think coherently **within a single workflow**.

---

## Long-Term Memory

Long-term memory persists **across multiple executions** of the graph. It represents accumulated experience rather than momentary context.

Examples include:
- User preferences
- Historical interactions
- Learned patterns
- Cached knowledge
- Behavioral insights
- Persistent notes or summaries

LangGraph does **not** impose a specific long-term memory solution. Instead, it provides the structure to integrate external systems such as:
- Databases
- Vector stores
- File systems
- Knowledge bases
- Memory APIs

Nodes can read from and write to these systems, while only **references, summaries, or identifiers** are stored in the state.

---

## Why This Separation Matters

Separating short-term and long-term memory is essential because:

- It prevents state from becoming bloated
- It keeps workflows efficient and fast
- It avoids unnecessary context overload
- It allows independent scaling of memory systems

Short-term memory supports **reasoning**.  
Long-term memory supports **learning**.

---

## How They Work Together

A typical pattern looks like this:

1. Long-term memory provides background knowledge
2. Short-term memory handles current reasoning
3. Decisions are made using short-term memory
4. Important insights are written back to long-term memory
5. Short-term memory is discarded at the end

This creates agents that feel:
- **Focused in the moment**
- **Experienced over time**

---

## Memory as a Design Choice

In LangGraph, memory is not accidental—it is **designed**.

You decide:
- What is remembered
- For how long
- Where it is stored
- How it influences decisions

This explicit control is what makes LangGraph suitable for **serious, production-grade agentic systems**.

---

## Key Takeaway

Memory is not just data—it is the **continuity of intelligence**.

By making memory explicit, structured, and inspectable, LangGraph turns agents from stateless responders into **evolving systems** that reason, adapt, and improve over time.

---

## Example: Memory in LangGraph


```python
#########################################################
# IMPORT REQUIRED LIBRARIES
#########################################################

# TypedDict for structured state
from typing import TypedDict, Annotated

# add_messages reducer appends new messages to conversation history
from langgraph.graph.message import add_messages

# Core LangGraph classes
from langgraph.graph import StateGraph, START, END

# LLM for reasoning
from langchain_openai import ChatOpenAI


#########################################################
# DEFINE STATE WITH MEMORY
#########################################################

class ChatState(TypedDict):
    # Stores full conversation history (short-term memory)
    messages: Annotated[list, add_messages]

    # Long-term memory storage
    long_term_memory: list


#########################################################
# INITIALIZE THE LANGUAGE MODEL
#########################################################

llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0
)


#########################################################
# NODE TO ADD SHORT-TERM MEMORY
#########################################################

def add_short_term_memory_node(state: ChatState):
    """
    Node simulating an AI response being added to short-term memory.
    Short-term memory is the message history.
    """
    user_message = ("user", "Remember this short-term info.")
    
    # Return new message to be appended
    return {
        "messages": [user_message]
    }


#########################################################
# NODE TO ADD LONG-TERM MEMORY
#########################################################

def add_long_term_memory_node(state: ChatState):
    """
    Node simulating storing key info in long-term memory.
    Long-term memory persists across sessions or multiple runs.
    """
    new_memory_entry = "Important fact stored in long-term memory."
    
    # Append to long-term memory
    return {
        "long_term_memory": state["long_term_memory"] + [new_memory_entry]
    }


#########################################################
# BUILD THE GRAPH
#########################################################

graph = StateGraph(ChatState)

# Register nodes
graph.add_node("short_term_memory", add_short_term_memory_node)
graph.add_node("long_term_memory", add_long_term_memory_node)

# Linear flow from start → short-term → long-term → end
graph.add_edge(START, "short_term_memory")
graph.add_edge("short_term_memory", "long_term_memory")
graph.add_edge("long_term_memory", END)

# Compile the graph
app = graph.compile()


#########################################################
# RUN THE GRAPH
#########################################################

# Initial state with empty memories
initial_state = {
    "messages": [],
    "long_term_memory": []
}

# Execute the graph
final_state = app.invoke(initial_state)

# Print memory contents
print("Short-term memory (messages):", final_state["messages"])
print("Long-term memory:", final_state["long_term_memory"])

```

---
